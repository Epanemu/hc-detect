{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3bba9a",
   "metadata": {},
   "source": [
    "## How to run the dnf_bias.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d6b46",
   "metadata": {},
   "source": [
    "### Example run:\n",
    "\n",
    "```bash\n",
    "python src/detect/dnf_bias/dnf_bias.py \n",
    "        dataset_path=src/detect/dnf_bias/data/ACSIncome_CA.csv \n",
    "        result_folder=results_dir \n",
    "        target=PINCP\n",
    "        protected=SEX,RAC1P,AGEP,POBP,_POBP,DIS,CIT,MIL,ANC,NATIVITY,DEAR,DEYE,DREM,FER,POVPIP\n",
    "        continuous=AGEP,PINCP,WKHP,JWMNP,POVPIP\n",
    "        feature_processing=POBP:100,OCCP:100,PUMA:100,POWPUMA:1000\n",
    "\n",
    "        model=MMD\n",
    "        seed=0\n",
    "        n_samples=1000000\n",
    "        train_samples=100000\n",
    "        time_limit=600\n",
    "        n_min=10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc26a09",
   "metadata": {},
   "source": [
    "### Command-line Flags\n",
    "\n",
    "- **`dataset_path`**  \n",
    "  Path to the input CSV file. Must include a header row and all feature columns, including the one named by `target`.\n",
    "\n",
    "- **`result_folder`**  \n",
    "  Directory where `output.txt` will be written. It will be created if it doesn’t exist.\n",
    "\n",
    "- **`target`**  \n",
    "  Name of the column in your CSV to treat as the binary target variable.\n",
    "\n",
    "- **`protected`**  \n",
    "  Comma-separated list of column names to treat as *protected* attributes (e.g. `SEX,RAC1P,AGEP`).  \n",
    "  Subgroups are only generated over these features.\n",
    "\n",
    "- **`continuous`**  \n",
    "  Comma-separated list of column names to treat as *continuous*. Those columns will use a numeric range (`min`,`max`) rather than per-value categories.\n",
    "\n",
    "- **`feature_processing`**  \n",
    "  Comma-separated `col:divisor` pairs, e.g. `POBP:100,OCCP:100`.  \n",
    "  Each matching column will be integer-divided by `divisor` before binarization—to reduce cardinality.\n",
    "\n",
    "- **`model`**  \n",
    "  Which distance metric to use for scoring subgroups. One of:\n",
    "  - `MSD` – Mean Subgroup Difference  \n",
    "  - `W1` – 1-Wasserstein (Earth Mover’s Distance)  \n",
    "  - `W2` – 2-Wasserstein  \n",
    "  - `TV` – Total Variation  \n",
    "  - `MMD` – Maximum Mean Discrepancy\n",
    "\n",
    "- **`seed`**  \n",
    "  Integer seed for any random sampling (subsampling rows, tie-breaking, etc.) to ensure reproducibility.\n",
    "\n",
    "- **`n_samples`**  \n",
    "  Maximum number of rows to sample from your dataset (default 1 000 000). If the CSV has more rows, it will be randomly subsampled down.\n",
    "\n",
    "- **`train_samples`**  \n",
    "  (Reserved) Intended to limit the number of training samples—currently not used but parsed for future extensions.\n",
    "\n",
    "- **`time_limit`**  \n",
    "  Time budget (in seconds) for the enumerative search. The loop will terminate early once this limit is reached.\n",
    "\n",
    "- **`n_min`**  \n",
    "  Minimum required subgroup support (number of rows). Any subgroup with fewer than `n_min` rows is automatically pruned.\n",
    "\n",
    "---\n",
    "\n",
    "#### Output\n",
    "\n",
    "After running, you’ll find:\n",
    "\n",
    "- **`<result_folder>/output.txt`**  \n",
    "  A summary of the search: max distance, best subgroup’s literals, total/skipped/checked counts, and elapsed time.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
